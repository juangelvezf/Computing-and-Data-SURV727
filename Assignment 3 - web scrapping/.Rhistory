src <- read_html(url)
print(url)
}
for(i in seq_along(east_areas)){
all_east_areas[[i]] <- read_csv(east_areas[[i]])
}
for(i in east_areas) {
url <- paste0("https://en.wikipedia.org/wiki/",i, sep = "")
src <- read_html(url)
print(url)
}
for (i in east_areas){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (1 in east_areas){
for (i in east_areas){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for(i in east_areas) {
url <- paste0("https://en.wikipedia.org/wiki/",i, sep = "")
src <- read_html(url)
print(url)
}
east_areas
for (i in east_areas){
url <- paste0("https://en.wikipedia.org/wiki/", i[1])
print(url)
}
east <- east_areas %>%
unnest_wider(east_areas)
east_areas1 <- data.frame(matrix(unlist(east_areas), nrow=length(east_areas), byrow=TRUE))
View(east_areas1)
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i[1])
print(url)
}
data.table::fread(paste(east_areas1, collapse = "\n"))
library(splitstackshape)
cSplit(east_areas1,"x",",")
csplit(east_areas1,"x",",")
library(splitstackshape)
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
View(east_areas1)
names(east_areas1)
cplit(east_areas1,"matrix.unlist.east_areas...nrow...length.east_areas...byrow...TRUE.",",")
cSplit(east_areas1,"matrix.unlist.east_areas...nrow...length.east_areas...byrow...TRUE.",",")
east_areas1 <- data.frame(matrix(unlist(east_areas), nrow=length(east_areas), byrow=TRUE))
View(east_areas1)
split(east_areas1, f = names1)
split(east_areas1)
names(east_areas1)
split(east_areas1, f = "matrix.unlist.east_areas...nrow...length.east_areas...byrow...TRUE.")
east_areas1 %>% separate("matrix.unlist.east_areas...nrow...length.east_areas...byrow...TRUE.")
east_areas1 <- data.frame(matrix(unlist(east_areas), byrow=TRUE))
east_areas1 <- data.frame(matrix(unlist(east_areas)))
View(east_areas1)
separate(east_areas1,
sep = ",")
separate(east_areas1,col
sep = ",")
separate(east_areas1,col,
sep = ",")
rm(list=ls())
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
paths_allowed("https://en.wikipedia.org/wiki/Grand_Boulevard,_Chicago")
wiki <- read_html("https://en.wikipedia.org/wiki/Grand_Boulevard,_Chicago")
nds <- html_table(wiki)
str(nds)
head(nds)
hist_pop <- nds [[2]]
hist_pop
pop <- hist_pop[2:10, -3]
pop
adj_places <- nds [[3]]
adj_places
head(nds) #the position is number 2
adj_places1 <- nds [[4]]
adj_places1
east_areas1 <- adj_places1 [1, 1]
east_areas1
east_areas <- adj_places [1, 1]
east_areas
east_areas1 <- gsub("\n", "_", east_areas1)
east_areas1
pops <- pop
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i[1])
print(url)
}
for(i in east_areas) {
url <- paste0("https://en.wikipedia.org/wiki/",i, sep = "")
src <- read_html(url)
print(url)
}
east_areas1 <- adj_places1 [1, 1]
east_areas1
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i[1])
print(url)
}
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas <- gsub("\n", "_", east_areas)
east_areas
adj_places1 <- nds [[4]]
adj_places1
east_areas1 <- adj_places1 [1, 1]
east_areas1
east_areas1 <- adj_places1 [1, 5]
east_areas1 <- adj_places1 [1, ]
east_areas1
east_areas1 <- adj_places1 [, ]
east_areas1
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas2 <- gsub("\n", "_", east_areas1)
east_areas2
east_areas1 <- adj_places1 [, ]
east_areas1
east_areas <- gsub("\n", "_", east_areas)
east_areas
pops <- pop
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas2 <- gsub("\n", "_", east_areas1)
east_areas2
east_areas2 <- gsub("_", east_areas1)
east_areas2 <- gsub("\n", east_areas1)
east_areas2 <- gsub("\n", "_", east_areas1)
east_areas2
east_areas1
east_areas1 <- adj_places1 [, ]
east_areas1
east_areas <- adj_places [1, 1]
east_areas
#option 1
for (i in east_areas){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
map( east_areas1, show )
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas2 <- list=as.list(east_areas1)
east_areas2 <- tibble_as_list(east_areas1)
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape","tibble")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
east_areas2 <- tibble_as_list(east_areas1)
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape","tibble")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
east_areas2 <- tibble_as_list(east_areas1)
east_areas2 <- lst(east_areas1)
east_areas2
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas3 <- gsub("\n", "_", east_areas2)
east_areas3
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
for (i in east_areas){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
east_areas <- gsub("\n", "_", east_areas)
east_areas
pops <- pop
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas1
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
1
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas1
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas1
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas1
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
lst(east_areas1)
east_areas2 <- lst(east_areas1)
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
View(east_areas1)
east_areas2 <- east_areas1 %>% drop_na()
View(east_areas2)
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
east_areas1
View(east_areas1)
with(east_areas1, split())
as.list(east_areas1)
print(url)
as.list(east_areas1)
print(url)
for (i in east_areas1){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
east_areas1 <- adj_places1 [, ]
east_areas1
View(east_areas1)
write_xlsx(east_areas1,"east_areas1.xlsx")
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape","tibble","readxl")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
write_xlsx(east_areas1,"east_areas1.xlsx")
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape","tibble","xlsx")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape","tibble","readxl")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape","tibble","xlsx")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape","tibble","writexl")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
write_xlsx(east_areas1,"east_areas1.xlsx")
#write_xlsx(east_areas1,"east_areas1.xlsx")
east_areas2 <- rio::import(here::here("east_areas2.xlsx"))
#write_xlsx(east_areas1,"east_areas1.xlsx")
east_areas2 <- rio::import(here::here("Assignment 3 - web scrapping","east_areas2.xlsx"))
View(east_areas2)
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
as_tibble_col(east_areas2)
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
#write_xlsx(east_areas1,"east_areas1.xlsx")
east_areas2 <- rio::import(here::here("Assignment 3 - web scrapping","east_areas2.xlsx"))
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas2[8]){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas2[1]){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in 1:east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
}
src <- read_html(url)
devtools::check(vignettes = TRUE)
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
print(url)
src <- read_html(url)
pops <- cbind(src)
}
pops <- pop
pop
for (i in east_areas2){
url <- paste0("https://en.wikipedia.org/wiki/", i)
src <- read_html(url)
print(url)
}
print(url)
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape","tibble","writexl")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
paths_allowed("https://en.wikipedia.org/wiki/Grand_Boulevard,_Chicago")
wiki <- read_html("https://en.wikipedia.org/wiki/Grand_Boulevard,_Chicago")
nds <- html_table(wiki)
str(nds)
head(nds) #the position is number 2
hist_pop <- nds [[2]]
hist_pop
pop <- hist_pop[2:11, -3]
pop
nds
adj_places <- nds [[4]]
adj_places
east_a <- adj_places [c(1,3,5), 3]
east_a
# as character
east_areas <- as.character(east_a)
east_areas
east_a$X3 <- gsub(" ", "_", east_a$X3)
View(east_a)
east_a$X3 <- gsub(" ", "_", east_a$X3)
print(east_areas$X3)
print(east_a$X3)
pops <- pop
for (i in east_a$X3){
url <- paste0("https://en.wikipedia.org/wiki/", i, sep = "")
print(url)
}
datar <- html_table(src)
for(i in east_areas$X3) {
url <- paste0("https://en.wikipedia.org/wiki/", i, sep="")
src <- read_html(url)
datar <- html_table(src)
pop1 <- datar[[2]]
print(pop1)
pop1 <- pop1[,-3]
colnames(pop1)<- c("Census_Year", "Population", "Change")
pop1<- pop1[-c(1,12), ]
part<- data.frame(pop1)
popu <- cbind(part,pops, popu)
}
for(i in east_a$X3) {
url <- paste0("https://en.wikipedia.org/wiki/", i, sep="")
src <- read_html(url)
datar <- html_table(src)
pop1 <- datar[[2]]
print(pop1)
pop1 <- pop1[,-3]
colnames(pop1)<- c("Census_Year", "Population", "Change")
pop1<- pop1[-c(1,12), ]
part<- data.frame(pop1)
popu <- cbind(part,pops, popu)
}
x <- 1:10
popu <- data.frame(x)
for(i in east_a$X3) {
url <- paste0("https://en.wikipedia.org/wiki/", i, sep="")
src <- read_html(url)
datar <- html_table(src)
pop1 <- datar[[2]]
print(pop1)
pop1 <- pop1[,-3]
colnames(pop1)<- c("Census_Year", "Population", "Change")
pop1<- pop1[-c(1,12), ]
part<- data.frame(pop1)
popu <- cbind(part,pops, popu)
}
popu
str(pops)
str(popu)
print(popu)
print(pops)
print(popu)
print(pops)
print(popu)
print(popu)
print(pops)
str(popu)
print(popu)
```{r, echo=FALSE results="hide"}
rm(list=ls())
packages = c("tidyverse", "xml2","rvest","jsonlite","robotstxt","RSocrata","splitstackshape","tibble","writexl")
package.check <- lapply(packages, FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}})
popu
x <- 1:10
popu <- data.frame(x)
for(i in east_a$X3) {
url <- paste0("https://en.wikipedia.org/wiki/", i, sep="")
src <- read_html(url)
datar <- html_table(src)
pop1 <- datar[[2]]
print(pop1)
pop1 <- pop1[,-3]
colnames(pop1)<- c("Census_Year", "Population", "Change")
pop1<- pop1[-c(1,12), ]
part<- data.frame(pop1)
popu <- cbind(part,pops, popu)
}
